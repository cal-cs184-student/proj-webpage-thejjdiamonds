<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1.0, shrink-to-fit=no">
<link href="assets/images/diamond.png" rel="icon" />
<title>Project 1</title>
<meta name="description" content="Your ThemeForest item Name and description">
<meta name="author" content="harnishdesign.net">

<!-- Stylesheet
============================== -->
<!-- Bootstrap -->
<link rel="stylesheet" type="text/css" href="assets/vendor/bootstrap/css/bootstrap.min.css" />
<!-- Font Awesome Icon -->
<link rel="stylesheet" type="text/css" href="assets/vendor/font-awesome/css/all.min.css" />
<!-- Magnific Popup -->
<link rel="stylesheet" type="text/css" href="assets/vendor/magnific-popup/magnific-popup.min.css" />
<!-- Highlight Syntax -->
<link rel="stylesheet" type="text/css" href="assets/vendor/highlight.js/styles/github.css" />
<!-- Custom Stylesheet -->
<link rel="stylesheet" type="text/css" href="assets/css/stylesheet.css" />
</head>

<body data-spy="scroll" data-target=".idocs-navigation" data-offset="125">

<!-- Preloader -->
<div class="preloader">
  <div class="lds-ellipsis">
    <div></div>
    <div></div>
    <div></div>
    <div></div>
  </div>
</div>
<!-- Preloader End --> 

<!-- Document Wrapper   
=============================== -->
<div id="main-wrapper"> 
  
  <!-- Header
  ============================ -->
  <header id="header" class="sticky-top"> 
    <!-- Navbar -->
    <nav class="primary-menu navbar navbar-expand-lg navbar-dropdown-dark">
      <div class="container-fluid">
        <!-- Sidebar Toggler -->
		<button id="sidebarCollapse" class="navbar-toggler d-block d-md-none" type="button"><span></span><span class="w-75"></span><span class="w-50"></span></button>
		
		<!-- Logo --> 
        <!-- <a class="logo ml-md-3" href="index.html" title="iDocs Template"> <img src="assets/images/logo.png" alt="iDocs Template"/> </a>  -->
		<span class="text-2 ml-2">Jasmine Lin and Jennifer Prince</span> 
        <!-- Logo End -->

       <!--  <ul class="social-icons social-icons-sm ml-lg-2 mr-2">
          <li class="social-icons-twitter"><a data-toggle="tooltip" href="http://www.twitter.com/harnishdesign/" target="_blank" title="" data-original-title="Twitter"><i class="fab fa-twitter"></i></a></li>
          <li class="social-icons-facebook"><a data-toggle="tooltip" href="http://www.facebook.com/harnishdesign/" target="_blank" title="" data-original-title="Facebook"><i class="fab fa-facebook-f"></i></a></li>
          <li class="social-icons-dribbble"><a data-toggle="tooltip" href="http://www.dribbble.com/harnishdesign/" target="_blank" title="" data-original-title="Dribbble"><i class="fab fa-dribbble"></i></a></li>
        </ul>
      </div> -->
    </nav>
    <!-- Navbar End --> 
  </header>
  <!-- Header End --> 
  
  <!-- Content
  ============================ -->
  <div id="content" role="main">
    
	<!-- Sidebar Navigation
	============================ -->
	<div class="idocs-navigation bg-light">
      <ul class="nav flex-column ">
        <!-- <li class="nav-item"><a class="nav-link active" href="#idocs_start">Overview</a>
        	<ul class="nav flex-column">
	        	<li class="nav-item"><a class="nav-link" href="index.html">Overview</a></li>
			</ul>
        </li> -->
        <li class="nav-item"><a class="nav-link" href="#idocs_layout">Project 1</a>
          <ul class="nav flex-column">
			<li class="nav-item"><a class="nav-link" href="#idocs_header">Task 1: Drawing Single-Color Triangles</a></li>
			<li class="nav-item"><a class="nav-link" href="#idocs_navbar">Task 2: Antialiasing by Supersampling</a></li>
			<li class="nav-item"><a class="nav-link" href="#idocs_sidebar">Task 3: Transforms</a></li>
			<li class="nav-item"><a class="nav-link" href="#idocs_footer">Task 4: Barycentric coordinates</a></li>
			<li class="nav-item"><a class="nav-link" href="#idocs_box_layout">Task 5: &quot;Pixel sampling&quot; for texture mapping</a></li>
			<li class="nav-item"><a class="nav-link" href="#idocs_content">Task 6: &quot;Level sampling&quot; with mipmaps for texture mapping</a></li>
          </ul>
        </li>
      </ul>
    </div>
    
    <!-- Docs Content
	============================ -->
    <div class="idocs-content">
      <div class="container"> 		
        
		<hr class="divider">
		
		<!-- Project 1: Overview
		============================ -->
        <section id="idocs_layout">
          <h2>Project 1: Overview</h2>
          <p><img src="images/lion.png" alt="rasterized lion" width="800px" align="middle"/></p>
          <p class="lead mb-5">In this project, we implemented a simple rasterizer that can draw SVG components. The rasterizer implements several interesting features, including supersampling, transforms, and texture mapping.</p>
        </section>
		
		
        <!-- Header
		============================ -->
        <section id="idocs_header">
          <h2>Task 1: Drawing Single-Color Triangles</h2>
          <p>Triangles are rasterized by sampling across the pixels of a given image. The simplest approach, which is how we implemented Task 1, is to sample the point at the center of each pixel. We check if the point is within the triangle we are rasterizing, and if so, fill in the whole corresponding pixel with its corresponding color. The process is as follows: </p>
          	<ul>
          		<li>We calculate the smallest bounding box of pixels around the triangle that we need to sample – in essence, we determine the four corners of the smallest rectangle that will fully enclose the triangle we want to draw. This way, our algorithm avoids checking pixels unnecessarily.</li>
          		<li>Iterating through the pixels in the bounding box in row major order, we calculate the center point of each pixel.
				At each point, we do the three line test calculations to check if it is within the triangle. For each pair of triangle vertices, we are determining on which half-plane the point resides in (i.e. we check if the point is above or below the line).</li>
				<li>To account for winding order, we check whether the point is always on the negative side of the three lines, or always on the positive side. If either of these cases are true, then the point is within the triangle.</li>
				<li>If the point is within the triangle, we fill the pixel in with it’s corresponding color.</li>
          	</ul>
          	<p>
			Here are two examples of our algorithm rasterizing some triangles. This simple sampling algorithm clearly leaves jagged edges and corners that are not as sharp, as there are less points sampled in the triangle. In other words, it doesn’t significantly reduce aliasing. In addition, this algorithm is no worse than one that checks each sample within the bounding box of the triangle since we do sample within the bounding box, thereby reducing the amount of pixels that we have to sample.
			</p>
			<p><img src="images/task1save.png" alt="test4 image 1" width="800px" align="middle"/></p>
			<p><img src="images/task1img1.png" alt="test4 image 1" width="800px" align="middle"/></p>
        </section>
		
		<hr class="divider">
		
		<!-- Navbar
		============================ -->
        <section id="idocs_navbar">
          <h2>Task 2: Antialiasing by Supersampling</h2>
		  <p>Adding supersampling will reduce aliasing, or at least diminish the look of the jagged lines. The lines are much sharper with supersampled rasterization, and the triangles that are rendered have a cleaner look.</p>
		  <p>The supersampling algorithm is very similar to the original triangle rasterizer, except for two big changes: how points are sampled within a pixel, and how the color that eventually fills the pixel is determined. Due to these changes, some other functions and data structures were used to help.</p>
		  <p>For our implementation, we iterate through the pixels in the bounding box of the triangle as usual. For every pixel we are on, we take n samples within the pixel instead of just one sample at the center of the pixel (n being the sample_rate). The samples are distributed evenly over the pixel, so there is another set of for loops sampling each of those points within a certain pixel. Now that the number of samples has increased by a factor of sample_rate times, we store the colors at each sample point in the sample_buffer array. The sample buffer size is also changed to account for supersampling, where it’s size is a result of sample_rate * width * height. This is different from how we just called fill_pixel for simple triangle rasterization.</p>
		  <p>Now to draw to the actual framebuffer, the work is done in the resolve_to_framebuffer function. For every pixel that needs to be drawn, we average the colors stored in the corresponding sample buffer for all the points that were sampled in that pixel. Then this averaged color is what the pixel color is set to. We did this by setting the corresponding color in the rgb_framebuffer_target array and accounted for the difference in dimension between the sample_buffer and the rgb_frambuffer. With this change to how the sample_buffer is used, we also edited the fill_pixel function so that it still draws lines and points correctly even with supersampling by having it modify the sample_buffer directly.</p>
		  <p>Specifically, these were the changes made to the original rasterizing pipeline:</p>
		  <ul>
		  	<li>The sample_buffer is resized to be larger whenever the sample_rate is changed.</li>
		  	<li>We made it so that supersampling will mainly affect the  triangles that are rasterized, not lines and points. When redraw is called to draw the lines for the square boundary on the picture, it won’t be fading away as the sampling rate goes up.</li>
		  	<li>Triangles are only drawn to the framebuffer once the entire triangle has been rasterized and is ready to be drawn (i.e. when resolve_to_framebuffer is called) and now directly as the triangle is being rasterized. This way, the background and foreground images stay cleanly separated.</li>
		  </ul>
		  <p>As you can see in the tip of the red triangle zoomed in, supersampling allows the edge to be more clearly defined and less jagged. As we increase the sampling_rate from 1 to 4 to 9 to 16, it gets better.</p>
		  <p><img src="images/task2img1.png" alt="test4 image 1" width="800px" align="middle"/></p>
		  <p><img src="images/task2img2.png" alt="test4 image 1" width="800px" align="middle"/></p>
		  <p><img src="images/task2img3.png" alt="test4 image 1" width="800px" align="middle"/></p>
		  <p><img src="images/task2img4.png" alt="test4 image 1" width="800px" align="middle"/></p>
		</section>

		<hr class="divider">
		
		<!-- Sidebar
		============================ -->
        <section id="idocs_sidebar">
          <h2>Task 3: Transforms</h2>
          <p>I rotated cubeman’s arms so that it looks like he is holding one hand at his waist and waving with the other hand. To make the bending arms look a bit more natural, those rotated forearm rectangles were also translated up and down and to the sides.</p>
          <p><img src="images/my_robot.png" alt="test4 image 1" width="800px" align="middle"/></p>
          <p>These are the matrices we implemented: </p>
          <p><img src="images/transformeq.png" alt="test4 image 1" width="800px" align="middle"/></p>
        </section>
		
        <hr class="divider">

        <!-- Footer
		============================ -->
        <section id="idocs_footer">
          <h2>Task 4: Barycentric coordinates</h2>
          <p>Barycentric coordinates are a coordinate system based on the vertices of a triangle. It provides a way to check if a point is within a triangle, and a way to linearly interpolate across the triangle. This linear interpolation isn’t just limited to position coordinates – it can be used to interpolate anything across a triangle, including color. This is what results in the lovely gradient we see in test7.svg, and also in these example triangles with three distinct colors at each corner:</p>
          <p><img src="images/test9.png" alt="test4 image 1" width="800px" align="middle"/></p>
          <p><img src="images/test7.png" alt="test4 image 1" width="800px" align="middle"/></p>
          <p>Barycentric coordinates are calculated from the three vertices of a triangle as follows:</p>
          <p><img src="images/baryeq.png" alt="test4 image 1" width="800px" align="middle"/></p>
			<p>
			Alpha, beta, and gamma end up being the values we want to weight the colors at each of the corresponding vertices to get the smooth gradient.
			</p>
        </section>
        
		<hr class="divider">
		
		<!-- Box Layout Style
		============================ -->
        <section id="idocs_box_layout">
          <h2>Task 5: "Pixel sampling" for texture mapping</h2>
          <div>
            <p>Pixel sampling is a process that converts a coordinate to a texture coordinate, thereby mapping a pixel to the texture map. Breaking this down, these were the general steps that were used to find the texture map coordinate: </p>
            <ul>
            	<li>For each rasterized screen sample (or their subpixels if we add in supersampling), we want to evaluate their barycentric coordinates, relative to the vertices of the triangle. From a geometric perspective, this can be seen as finding the proportional distance away from the triangle vertices.</li>
            	<li>We can then find the texture coordinate with the barycentric coordinates by multiplying alpha, beta and gamma with the vertices of the triangle on the texture map (effectively applying the equation of (x, y) = (alpha * A) + (beta * B) + (gamma * C)) and then scaling it by the size of the mipmap level (which at this stage, is just 0).</li>
            	<li>Now that we have our corresponding texture map coordinate, we can use one of our pixel sampling methods, nearest or bilinear, to get the information we want from the texture map.</li>
            </ul>
            <p><strong>Nearest sampling</strong> involves finding the closest pixel on the texture map relative to our current texture coordinate. This effectively means we round to obtain that nearest pixel. For our implementation of this sampling method, we scaled the coordinates by the (width - 1) and (height - 1) of the texture map inside the function to get the texture coordinate (the main reason we decremented the height and width by 1 was to account for indexing). We then rounded it to the nearest pixel. This gets us the desired texture that we want to use.</p>
            <p><strong>Bilinear sampling</strong>, on the other hand, can be interpreted as interpolating or “averaging” the colors between the four pixels around our texture coordinate. So instead of using one pixel in bilinear sampling, we rely on four to find the texture we want to return. For this implementation, we started out similarly to nearest sampling, where we had to scale by the width and height of the mipmap. However, by using the floor and ceil function, we then calculated the horizontal and vertical offset, specifically the horizontal and vertical difference from the four nearest points. We then grabbed the associated texture for each of the four nearest points and interpolated them (two times horizontally, and one time vertically), which resulted in the desired texture.</p>
            <p>Images:</p>
            <ul>
            	<li>Top Left: Nearest Sampling, Sampling Rate 1</li>
            	<li>Bottom Left: Nearest Sampling, Sampling Rate 16</li>
            	<li>Top Right: Bilinear, Sampling Rate 1</li>
            	<li>Bottom Right: Bilinear Sampling, Sampling Rate 16</li>
            </ul>
            <div class="row">
			  <div class="column">
			    <img src="images/Task5_Nearest_1.png" alt="Snow" width="400px">
			  </div>
			  <div class="column">
			    <img src="images/Task5_Nearest_16.png" alt="Forest" width="400px">
			  </div>
			</div>
			<div class="row">
			  <div class="column">
			    <img src="images/Task5_Bilinear_1.png" alt="Snow" width="400px">
			  </div>
			  <div class="column">
			    <img src="images/Task5_Bilinear_16.png" alt="Forest" width="400px">
			  </div>
			</div>
			<!-- <table>
			  <tr>
			    <th>Company</th>
			    <th>Contact</th>
			  </tr>
			  <tr>
			    <td><img src="Task5_Nearest_1.png" alt="Snow" width="400px"></td>
			    <td><img src="Task5_Nearest_16.png" alt="Forest" style="width:100%"></td>
			  </tr>
			  <tr>
			    <td>Centro comercial Moctezuma</td>
			    <td>Francisco Chang</td>
			  </tr>
			</table> -->
            <p>To compare between the different images, we zoomed in on an island. Comparing between both sampling methods and sampling rate, we first look at both methods when they’re sampled at a rate of 1 pixel. With an up close shot, we can see that with nearest sampling, there’s a bit more color variation than there is in bilinear sampling. In other words, if we were to focus on one pixel, there would be more color variation around it. The same can be said with a sampling rate of 16, so with bilinear sampling, overall, we tend to see “smoother” or more blended pixels and lines (and with the image above, it creates a more smooth map). This difference becomes more apparent when we’re working with sharp lines and especially with not as many colors - since bilinear sampling “averages” out the color, it becomes more distinct which sampling method is which based on the coloration of individual pixels. </p>
          </div>
        </section>
		
		<hr class="divider">
		
		<!-- Content
		============================ -->
        <section id="idocs_content">
          <h2>Task 6: "Level sampling" with mipmaps for texture mapping</h2>
          <p>Level sampling is a process that refers to sampling from mipmaps, which can be thought of as different versions of a texture map where each version has some varying resolution or detail. Generally speaking, the higher you go up in mipmap levels, the lower the resolution becomes (and vice versa). With level sampling, we’re able to pick and choose which resolution we want to show for a certain pixel.</p>
          <p>Our implementation of level sampling was done in rasterize_textured_triangle. The overall structure of it was similar to what was done in previous methods, rasterize_triangle and rasterize_interpolated_color_triangle. The main process is as follows: </p>
          <ul>
          	<li>For each rasterized screen sample (or their subpixels if supersampling was included), we calculated the barycentric coordinates for three points: (x, y), (x + 1), (x, y + 1). The main reason for this is because we wanted to apply the formula of  <img src="images/task6eq.png" alt="test4 image 1" width="800px" align="middle"/></li>
          	<li>By calculating the barycentric coordinates of those three points, we could obtain the derivatives as stated in the formula. The derivative can be thought of as an instantaneous rate of change, so once we computed the barycentric coordinates and found a corresponding point on the texture map, we could subtract them to obtain the derivative. More specifically, let’s say the vector v1 represents the point on the texture map of (x, y), v2 represents it for (x + 1, y) and v3 and represents it for (x, y + 1), then v2 - v1 and v3 - v1 will give us the needed derivatives.</li>
          	<li>Once inside the get_level function, we scaled by the width and height of the mipmap accordingly, and then applied the formula to find the level. This involved calculating the expressions under the square root, which is finding the norm or magnitude of those vectors, taking the max, and then finding the log base 2 of it. And finally, we would get our desired mipmap level.</li>
          </ul>
          <p>From here, we needed to get our desired texture point from the mipmap, and the means to get it was dependent on the type of level sampling we used:</p>
          <ul>
          	<li><strong>Always level 0:</strong> This means we would always sample from the lowest level, or level 0, where it was full resolution. With this choice, we would pixel sample normally, as we had done in Task 5. </li>
          	<li><strong>Nearest D (nearest level):</strong> This involved choosing the level that was considered the closest. Since there was a certain limit on the valid choices of mipmap level, we had to clamp down on the valid choices (i.e. if the calculated level was less than 0, we set the level to 0 and vice versa if it was greater than the size of the mipmap). We would then pass in the closest level into the pixel sampling functions that were implemented in Task 5. </li>
          	<li><strong>Linear interpolation:</strong> This choice involved “interpolation” of the levels. After we calculated the level, we wanted to find the weights that we would use to calculate the weighted average of the pixel sampling methods. In this case, the weight would be considered the difference between the level and the ones above it and below it. So depending on the type of pixel sampling method, the floor(level) and the ceil(level) would be passed into the appropriate methods and we would use the result to find the weighted average based on the weights we found earlier. And from there, it would return the desired texture we wanted.</li>
          </ul>
          <p>Now, there are three available methods we can use to create our image, with each method having its own tradeoffs. With level sampling, we use a significant more amount of memory, since we need to store the different levels. But in turn, it produces notable results for anti-aliasing and is faster than supersampling. Pixel sampling, on the other hand, doesn’t have as much memory overhead and tends to be faster compared to other methods, but can lead to more rendering artifacts. Depending on the pixel sampling method, bilinear can be slower than nearest pixel sampling. Finally, supersampling is the most expensive among the three, in terms of memory and speed, but it also significantly reduces aliasing. </p>
          <p>Example:</p>
          <ul>
          	<li>Top Left: L_Zero and P_Nearest</li>
          	<li>Bottom Left: L_Zero and P_Linear</li>
          	<li>Top Right: L_Nearest and P_Nearest</li>
          	<li>Bottom Right: L_Nearest and P_Linear</li>
          </ul>
          <div class="row">
			  <div class="column">
			    <img src="images/Task6ZeroL_PNearest.png" alt="Snow" width="400px">
			  </div>
			  <div class="column">
			    <img src="images/Task6NearestL_PNearest.png" alt="Forest" width="400px">
			  </div>
			</div>
			<div class="row">
			  <div class="column">
			    <img src="images/Task6ZeroL_PLinear.png" alt="Snow" width="400px">
			  </div>
			  <div class="column">
			    <img src="images/Task6NearestL_PLinear.png" alt="Forest" width="400px">
			  </div>
			</div>
          <p>Looking at the images with varying level sampling and pixel sampling, there is a notable difference between all of them. With just level zero and nearest pixel sampling, we result in an image that has more aliasing than the other images. Level zero and bilinear pixel sampling reduces the aliasing to a certain extent. With nearest level sampling, it smooths out the images too, with a combination of nearest level and bilinear pixel sampling producing the most smooth image (with the edges more “blurred” out).</p>
        </section>
		  
  
</div>
<!-- Document Wrapper end --> 

<!-- Back To Top --> 
<a id="back-to-top" data-toggle="tooltip" title="Back to Top" href="javascript:void(0)"><i class="fa fa-chevron-up"></i></a> 

<!-- JavaScript
============================ -->
<script src="assets/vendor/jquery/jquery.min.js"></script> 
<script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script> 
<!-- Highlight JS -->
<script src="assets/vendor/highlight.js/highlight.min.js"></script> 
<!-- Easing --> 
<script src="assets/vendor/jquery.easing/jquery.easing.min.js"></script> 
<!-- Magnific Popup --> 
<script src="assets/vendor/magnific-popup/jquery.magnific-popup.min.js"></script> 
<!-- Custom Script -->
<script src="assets/js/theme.js"></script>
</body>
</html>
